{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iRV5iLyq-DM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Airline Sentiment Analysis Using RNN**\n",
        "**PROJECT DETAIL**: 1.HIMANSHI SHARMA(055012)                                         \n",
        "                  \n",
        "                  2.MUSKAN BOHRA (055025)\n",
        "## **Objective**\n",
        "The goal of this project is to analyze and classify sentiments expressed in tweets about major U.S. airlines using Recurrent Neural Networks (RNN). The task involves preprocessing tweet text data, training an RNN model to classify sentiments into negative and non-negative (positive and neutral), and visualizing key insights that can help airlines improve their services and reputation.\n",
        "Source: The dataset is fetched using the yfinance library.\n",
        "\n",
        "Ticker Used: ^NSEI (Nifty 50 index)\n",
        "\n",
        "Period: Last 5 years (approx.)\n",
        "\n",
        "Interval: 1 day\n",
        "\n",
        "**Columns Used:**\n",
        "\n",
        "Open\n",
        "\n",
        "High\n",
        "\n",
        "Low\n",
        "\n",
        "Close\n",
        "\n",
        "Adj Close\n",
        "\n",
        "Volume\n",
        "\n",
        "Among these, the Close price is primarily used for training and prediction.\n",
        "---\n",
        "\n",
        "## **1. Installing & Importing Libraries**\n",
        "We begin by installing and importing essential Python libraries needed for data analysis, visualization, and building deep learning models using PyTorch.\n",
        "\n",
        "Libraries used:\n",
        "- `pandas`, `numpy`: Data handling\n",
        "- `matplotlib`, `seaborn`, `wordcloud`: Data visualization\n",
        "- `torch`, `torch.nn`, `torch.optim`: Neural network modeling\n",
        "- `sklearn`: Train-test split and model evaluation\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Uploading and Extracting the Dataset**\n",
        "The dataset, in zipped format, is uploaded and extracted into the Colab environment. The file `Tweets.csv` is read using pandas for further processing.\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Load Dataset**\n",
        "The dataset contains multiple fields, but we select only two columns:\n",
        "- `text`: The tweet content\n",
        "- `airline_sentiment`: The sentiment label (positive, negative, or neutral)\n",
        "\n",
        "We then simplify the sentiment labels by mapping:\n",
        "- `negative` → 0\n",
        "- `neutral` and `positive` → 1\n",
        "\n",
        "This transforms the problem into a binary classification task: negative vs. non-negative.\n",
        "\n",
        "---\n",
        "\n",
        "## **4. Preprocessing**\n",
        "To clean the tweet text data, we define a function that:\n",
        "- Removes URLs and mentions\n",
        "- Removes special characters\n",
        "- Converts text to lowercase\n",
        "\n",
        "Each tweet is then cleaned and stored in a new column.\n",
        "Download stock data using yfinance.\n",
        "\n",
        "Select Close column for time series analysis.\n",
        "\n",
        "Normalize the data using MinMaxScaler from sklearn.preprocessing to scale values between 0 and 1.\n",
        "\n",
        "Create sequences for RNN input:\n",
        "\n",
        "Time steps: 60 days.\n",
        "\n",
        "The next day’s close price is the target.\n",
        "\n",
        "Train-Test Split:\n",
        "\n",
        "Training Data: 80%\n",
        "\n",
        "Testing Data: 20%\n",
        "\n",
        " **Visualization:**\n",
        "The original and scaled stock price data were plotted for better understanding of trends and patterns.\n",
        "\n",
        "---\n",
        "\n",
        "### **Tokenization and Vocabulary**\n",
        "- We tokenize the cleaned text into words and count word frequency.\n",
        "- A vocabulary dictionary is created to map each word to a unique integer.\n",
        "- Each tweet is then represented as a sequence of integers using this vocabulary.\n",
        "\n",
        "---\n",
        "\n",
        "### **Padding Sequences**\n",
        "Tweets vary in length. To make them uniform, all sequences are padded (or truncated) to a fixed length (50 words). This ensures that input data is consistent for the RNN.\n",
        "\n",
        "---\n",
        "\n",
        "## **5. Train-Test Split**\n",
        "The data is split into training (80%) and test (20%) sets. This is essential to train the model on one set and evaluate it on another to avoid overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "## **6. DataLoader Preparation**\n",
        "A custom `TweetDataset` class is created to:\n",
        "- Convert inputs and labels to PyTorch tensors\n",
        "- Use PyTorch’s `DataLoader` for efficient batching and shuffling\n",
        "\n",
        "This prepares the data for RNN training in manageable mini-batches.\n",
        "\n",
        "---\n",
        "\n",
        "## **7. RNN Model Definition**\n",
        "The model consists of:\n",
        "- **Embedding layer**: Converts word indices to dense vectors\n",
        "- **LSTM layer**: Captures sequential relationships in text\n",
        "- **Fully Connected (Linear) layer**: Produces a single output value\n",
        "- **Sigmoid activation**: Converts output to a probability (0–1)\n",
        "\n",
        "The model is initialized with appropriate vocabulary size, embedding dimensions, and hidden layer size.\n",
        "\n",
        "---\n",
        "**Model Architecture**\n",
        "Model Type: Recurrent Neural Network (RNN)\n",
        "\n",
        "Framework: Keras (TensorFlow backend)\n",
        "\n",
        " Layers Used:\n",
        "SimpleRNN Layer:\n",
        "\n",
        "Units: 50\n",
        "\n",
        "Activation: 'tanh'\n",
        "\n",
        "Return sequences: True (to stack another RNN layer)\n",
        "\n",
        "SimpleRNN Layer:\n",
        "\n",
        "Units: 50\n",
        "\n",
        "Return sequences: False\n",
        "\n",
        "Dense Layer:\n",
        "\n",
        "Units: 1 (for regression output)\n",
        "\n",
        " **Model Summary:**\n",
        "Total Parameters: ~5,151\n",
        "\n",
        "Loss Function: mean_squared_error\n",
        "\n",
        "Optimizer: adam\n",
        "\n",
        "\n",
        "\n",
        "## **8. Model Training**\n",
        "The training loop runs for 5 epochs using:\n",
        "- **Binary Cross-Entropy Loss** for classification\n",
        "- **Adam Optimizer** for gradient updates\n",
        "\n",
        "After each epoch, loss is printed, and a loss curve is plotted to visualize the model’s learning process.\n",
        "\n",
        "---\n",
        "\n",
        "## **9. Model Evaluation**\n",
        "The model is evaluated on the test set by:\n",
        "- Generating predictions\n",
        "- Comparing with true labels\n",
        "- Calculating **accuracy**\n",
        "- Plotting a **confusion matrix** to understand prediction errors\n",
        "\n",
        "**Predictions:**\n",
        "The model’s predictions were inverse-transformed back to original scale using MinMaxScaler.inverse_transform().\n",
        "\n",
        "The predicted stock prices were compared with the actual values using plots.\n",
        "\n",
        "Evaluation Metrics:\n",
        "Mean Squared Error (MSE)\n",
        "\n",
        "Root Mean Squared Error (RMSE)\n",
        "\n",
        "These metrics help quantify how close the predictions are to actual prices.\n",
        "---\n",
        "\n",
        "## **10. Data Visualization**\n",
        "Multiple visualizations are created to understand the dataset and insights:\n",
        "\n",
        "### **Word Clouds**\n",
        "- For **negative** tweets: Common words expressing dissatisfaction\n",
        "- For **non-negative** tweets: Words representing positive or neutral experiences\n",
        "\n",
        "### **Tweet Length Distribution**\n",
        "- Shows how the length of tweets varies with sentiment\n",
        "- Helps understand if longer tweets are more likely to be negative/positive\n",
        "\n",
        "### **Airline-wise Negative Sentiment**\n",
        "- Bar chart showing which airlines receive the most negative tweets\n",
        "- United Airlines had the most, indicating potential service issues\n",
        "Plots generated:\n",
        "\n",
        "Actual vs Predicted Prices (Test Set)\n",
        "\n",
        "Training vs Validation Loss\n",
        "\n",
        "Historical Prices for understanding trends\n",
        "\n",
        "These visualizations provide a clear picture of model performance.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## **11. Managerial Insights**\n",
        "- Most tweets were negative, reflecting dissatisfaction with airline services.\n",
        "- United Airlines had the highest count of negative tweets.\n",
        "- The most common issues were delays, baggage loss, and customer service.\n",
        "- Businesses can use real-time sentiment monitoring to mitigate PR issues and improve customer support.\n",
        "\n",
        "---\n",
        " **12.Future Scope**\n",
        "\n",
        "Incorporate LSTM or GRU for better sequence modeling.\n",
        "\n",
        "Add technical indicators like RSI, MACD for richer feature set.\n",
        "\n",
        "Try multi-step forecasting instead of one-step prediction.\n",
        "\n",
        "Use more granular data like hourly stock prices.\n",
        "\n",
        "\n",
        "**13. Challenges and Limitations**\n",
        "\n",
        "Class Imbalance: The dataset was dominated by negative tweets (~63%), which may bias the model.\n",
        "\n",
        "Sarcasm Detection: The RNN model may fail to capture sarcastic tones or contextually ambiguous expressions.\n",
        "\n",
        "Model Simplicity: While RNNs are powerful, Transformer-based models (like BERT) can provide higher accuracy in sentiment classification tasks.\n",
        "\n",
        "Vocabulary Limitation: Words not seen in the training set (out-of-vocabulary) are ignored, which may affect predictions.\n",
        "\n",
        "**14. Future Work**\n",
        "\n",
        "Several enhancements can be implemented to improve performance and deployment readiness:\n",
        "\n",
        "Use of pre-trained word embeddings like GloVe or FastText to improve word representation.\n",
        "\n",
        "Replace the simple LSTM with Bidirectional LSTM (BiLSTM) to capture both past and future context.\n",
        "\n",
        "Expand the model to multi-class sentiment classification (negative, neutral, positive).\n",
        "\n",
        "Deploy the model using a Flask or Streamlit interface for real-time tweet classification.\n",
        "\n",
        "Integrate Twitter API to fetch live tweets and classify sentiment continuously.\n",
        "\n",
        "Implement attention mechanisms to focus on the most relevant words in a tweet during classification.\n",
        "\n",
        "\n",
        "## **15. Conclusion**\n",
        "The project demonstrates how RNNs can be effectively used for sentiment classification from social media text. The model was successfully trained on airline tweets and achieved promising accuracy on the test set. Visualizations provided meaningful insights into customer sentiment that can help airlines refine their operations.\n",
        "\n",
        "This end-to-end solution showcases the real-world application of deep learning and NLP for customer feedback analysis.\n",
        "This project successfully implemented an RNN model for stock price forecasting. It covered end-to-end processes from data collection to model deployment-ready predictions. While RNNs can model temporal relationships, performance can improve by using more advanced architectures like LSTMs.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xAe7EbPGq-rV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8V_xW6sVvD4e"
      }
    }
  ]
}
